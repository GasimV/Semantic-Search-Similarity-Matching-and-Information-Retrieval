{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embeddings_len):\n",
    "        super(CustomRNN, self).__init__()\n",
    "\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embeddings_len)\n",
    "        self.lstm = nn.LSTM(input_size=embeddings_len, hidden_size=embeddings_len//2, num_layers=3, batch_first=True)\n",
    "        # self.fc_in = nn.Linear(embeddings_len//2, embeddings_len//2)\n",
    "        # self.fc_out = nn.Linear(embeddings_len//2, embeddings_len//2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.embeddings(x)\n",
    "        out, _ = self.lstm(out)\n",
    "        # out = self.fc_in(out[-1])\n",
    "        out = self.relu(out[-1])\n",
    "        # out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from stemmer_lib.stemmer import Stemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    tokenizer_dict = json.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_dict = {v:k for k, v in enumerate(tokenizer_dict) if len(v) >= 3}\n",
    "tokenizer_dict = {v:k for k, v in enumerate(tokenizer_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(string:str) -> list[int]:\n",
    "    string = re.sub(r'\\d', '', string)\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    stems = stemmer.stem_words(string.lower().split())\n",
    "    func = lambda x: tokenizer_dict[x] if x in tokenizer_dict else tokenizer_dict.get(\"unknown\")\n",
    "    stems = torch.tensor(list(map(func, stems)))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"query\"] = data[\"query\"].apply(lambda x: tokenizer(str(x)))\n",
    "data[\"context\"] = data[\"context\"].apply(lambda x: tokenizer(str(x)))\n",
    "data[\"probability\"] = data[\"probability\"].apply(lambda x: -1 if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(\"probability\", axis=1)\n",
    "target = data[\"probability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=12345, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomRNN(vocab_size=vocab_size, embeddings_len=1024).to(device)\n",
    "optimazer = optim.Adam(model.parameters())\n",
    "citeration = nn.CosineEmbeddingLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:10, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:16, 36.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:13, 37.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:07, 38.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:12, 37.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:12, 37.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.2914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:10, 37.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.2699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:13, 37.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.2438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:13, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.2317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7182it [03:14, 36.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.2235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomRNN(\n",
       "  (embeddings): Embedding(15794, 1024)\n",
       "  (lstm): LSTM(1024, 512, num_layers=3, batch_first=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.01)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for query, context, label in tqdm(zip(features_train[\"query\"], features_train[\"context\"], target_train)):\n",
    "        # try:\n",
    "        optimazer.zero_grad()\n",
    "        \n",
    "        query = query.to(device)\n",
    "        context = context.to(device)\n",
    "        label = torch.tensor(label).to(device)\n",
    "\n",
    "        query = model(query)\n",
    "        context = model(context)\n",
    "\n",
    "        loss = citeration(query, context, label)\n",
    "        loss.backward()\n",
    "        optimazer.step()\n",
    "        total_loss += loss.item()\n",
    "        # except:\n",
    "        #     continue\n",
    "        \n",
    "    average_loss = total_loss / len(features_train)\n",
    "    print(f'Epoch [{_+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = list(map(lambda x: 0 if x == -1 else x, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2394it [00:18, 129.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for query, context in tqdm(zip(features_test[\"query\"], features_test[\"context\"])):\n",
    "    query = query.to(device)\n",
    "    context = context.to(device)\n",
    "\n",
    "    query = model(query).to(\"cpu\").detach().numpy().reshape(1, -1)\n",
    "    context = model(context).to(\"cpu\").detach().numpy().reshape(1, -1)\n",
    "    predictions.append(round(cosine_similarity(query, context)[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = accuracy_score(target_test, predictions)\n",
    "recall = recall_score(target_test, predictions)\n",
    "f1 = f1_score(target_test, predictions)\n",
    "precision = precision_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6876\n",
      "Precision: 0.6755\n",
      "Recall: 0.7119\n",
      "F1: 0.6932\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Accuracy: {accuracy_score:.4f}\n",
    "Precision: {precision:.4f}\n",
    "Recall: {recall:.4f}\n",
    "F1: {f1:.4f}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('model.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "#     f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
