{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from stemmer_lib.stemmer import Stemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(\n",
    "        d_model=10,\n",
    "        nhead=10\n",
    "    ),\n",
    "    num_layers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizer.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    tokenizer_dict = json.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_dict = {v:k for k, v in enumerate(tokenizer_dict) if len(v) >= 3}\n",
    "tokenizer_dict = {v:k for k, v in enumerate(tokenizer_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(string:str) -> list[int]:\n",
    "    string = re.sub(r'\\d', '', string)\n",
    "    string = re.sub(r'[^\\w\\s]', '', string)\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    stems = stemmer.stem_words(string.lower().split())\n",
    "    func = lambda x: tokenizer_dict[x] if x in tokenizer_dict else tokenizer_dict.get(\"unknown\")\n",
    "    stems = torch.tensor(list(map(func, stems)))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"query\"] = data[\"query\"].apply(lambda x: tokenizer(str(x)))\n",
    "data[\"context\"] = data[\"context\"].apply(lambda x: tokenizer(str(x)))\n",
    "data[\"probability\"] = data[\"probability\"].apply(lambda x: -1 if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(\"probability\", axis=1)\n",
    "target = data[\"probability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, random_state=12345, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, output_dim, nhead, num_encoder_layers, hidden_dim, tokens_max_length=512, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.position = nn.Embedding(tokens_max_length, hidden_dim)\n",
    "        self.transformer = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead, batch_first=True,\n",
    "                                                                            dropout=dropout), num_layers=num_encoder_layers)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)\n",
    "        t, k = src.size()\n",
    "        positions = torch.arange(t).to(device)\n",
    "        positions = self.position(positions)[:, :].expand(t, k)\n",
    "        src = src + positions\n",
    "        output = self.transformer(src)\n",
    "        output = output.mean(dim=0)  \n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 512   \n",
    "nhead = 8\n",
    "num_encoder_layers = 1\n",
    "hidden_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size, output_dim, nhead, num_encoder_layers, hidden_dim).to(device)\n",
    "optimazer = optim.Adam(model.parameters(), lr=0.001)\n",
    "citeration = nn.CosineEmbeddingLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for query, context, label in tqdm(zip(features_train[\"query\"], features_train[\"context\"], target_train)):\n",
    "        optimazer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            query = query.to(device)[:512]\n",
    "        except:\n",
    "            query = query.to(device)\n",
    "\n",
    "        try:\n",
    "            context = context.to(device)[:512]\n",
    "        except:\n",
    "            context = context.to(device)\n",
    "\n",
    "        label = torch.tensor(label).to(device)\n",
    "\n",
    "        query = model(query)\n",
    "        context = model(context)\n",
    "\n",
    "        loss = citeration(query, context, label)\n",
    "        loss.backward()\n",
    "        optimazer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    average_loss = total_loss / len(features_train)\n",
    "    print(f'Epoch [{_+1}/{num_epochs}], Loss: {average_loss:.4f}')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "target_test = list(map(lambda x: 0 if x == -1 else x, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query, context in tqdm(zip(features_test[\"query\"], features_test[\"context\"])):\n",
    "    try:\n",
    "        query = query.to(device)[:512]\n",
    "    except:\n",
    "        query = query.to(device)\n",
    "\n",
    "    try:\n",
    "        context = context.to(device)[:512]\n",
    "    except:\n",
    "        context = context.to(device)\n",
    "\n",
    "    query = model(query).to(\"cpu\").detach().numpy().reshape(1, -1)\n",
    "    context = model(context).to(\"cpu\").detach().numpy().reshape(1, -1)\n",
    "    predictions.append(round(cosine_similarity(query, context)[0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(map(lambda x: 0 if x == -1 else x, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = accuracy_score(target_test, predictions)\n",
    "recall = recall_score(target_test, predictions)\n",
    "f1 = f1_score(target_test, predictions)\n",
    "precision = precision_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"Accuracy: {accuracy_score:.4f}\n",
    "Precision: {precision:.4f}\n",
    "Recall: {recall:.4f}\n",
    "F1: {f1:.4f}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
